{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratório Elastic Search\n",
    "\n",
    "## Contexto\n",
    "O objetivo deste laboratório é explorar diferentes mecanismos de busca dentro e fora do Elastic Search!\n",
    "Para isto, iremos explorar uma base de verificações de notícia de agência de checagem chamada Lupa.\n",
    "O papel de uma agência de checagem é analisar uma notícia e verificar sua veracidade, gerar um veredito e retornar o veredito da sua análise.\n",
    "\n",
    "Neste laboratório, iremos nos preocupar apenas com o texto da análise e em como recuperá-los através de diferentes estratégias de busca.\n",
    "\n",
    "## Tarefa\n",
    "- Cada uma das equipes receberá 3 queries e deverá montar mais 3 queries (pergunta ou declaração textual para realizar a busca). As equipes podem se inspirar nas notícias fornecidas (.csv) para montá-las.\n",
    "- Com as 6 queries em mãos, cada grupo irá realizar 4 tipos de busca. Uma busca léxica com BM25 (pelo ElasticSearch), uma busca semântica (pelo ElasticSearch), uma busca híbrida (manualmente utilizando as duas buscas anteriores) e uma estratégia de busca de sua preferência (busca criativa) diferente das anteriores.\n",
    "    - As buscas possuem métodos de pré-processamento, sintam-se livres para testar diferentes combinações dos pré-processamentos em quaisquer uma das buscas!\n",
    "    - Inclusive as equipes podem criar outro métodos de pré-processamento.\n",
    "    - A busca criativa pode ser inspirada na busca léxica, semântica, híbrida ou algo totalmente novo, o importante é que ela traga bons resultados para na competição!\n",
    "- Para cada uma das 4 buscas, os grupos devem coletar os top 10 resultados para as 6 queries, resultando em 240 resultados. Diferentes estratégias de busca tendem a ter intersecção entre si nos resultados, então o número de resultados únicos será bem menor que 240 (não se preocupem).\n",
    "- A próxima etapa é de anotação, os grupos devem anotar o quão bom cada resultado é em relação com à query.\n",
    "    - A rotulação deve possui uma gradação em 3 níveis:\n",
    "        - 0: Não é Relevante\n",
    "        - 1: Pouco Relevante\n",
    "        - 2: Muito Relevante\n",
    "    - Os grupos só precisam anotar os resultados únicos agrupados por query, ou seja, se um mesmo resultado for encontrado na busca léxica da query A e na busca semântica da query A, ele só precisa ser anotado uma única vez (pois anotação deste resultado é igual para ambas as buscas). O código abaixo já realiza esta otimização no processo de rotulagem.\n",
    "Entretanto a anotação de um mesmo resultado na busca léxica da query A pode ser diferente da anotação na busca semântica da query B.\n",
    "    - Os resultados desta rotulação serão importantes para que o seu grupo saiba o quão boa sua busca é e como ela se compara com as buscas \"tradicionais\".\n",
    "\n",
    "## Artefatos entregáveis\n",
    "- As 3 queries definidas pela equipe.\n",
    "- A implementação da busca criativa, bem com seus imports, arquivos de dependências (requirements.txt), configurações etc.\n",
    "- Todos os resultados da busca.\n",
    "- Este notebook atualizado e funcionando com o botão \"Rodar tudo\".\n",
    "\n",
    "## Competição\n",
    "A competição será realizada através da comparação da sua implementação da busca criativa com uma base interna.\n",
    "Para que você atinja um bom desempenho na competição é importante se atentar ao seu processo de criação de queries e de rotulação, pois ele será o guia em o quão boa sua busca está se saindo!\n",
    "\n",
    "Esta competição irá utilizar o NDCG score e média dos scores para verificar qual grupo obteve a melhor ordenação média dos resultados e melhor obtenção de resultados.\n",
    "\n",
    "## Ferramental\n",
    "Para executar este lab não é necessário uma máquina com GPU, mas a máquina deve ter capacidade de virtualização, além de possui o Docker e o python instalado.\n",
    "\n",
    "Será utilizados o ElasticSearch (e opcionalmente o Kibana) no ambiente docker.\n",
    "\n",
    "É recomendado o uso de Python 3.12 para realizar o lab, além de um venv ou ambiente conda.\n",
    "Você deve instalar as dependências do requirements.txt.\n",
    "\n",
    "## Detalhes\n",
    "Assim que o grupo executar suas buscas será gerada a primeira planilha (search_results_for_labeling.xlsx), o grupo deve rotulá-la e em seguida rodar a avaliação do código (NDCG e média).\n",
    "Após a rotulação ser finalizada, execute o código que gera a \"search_results.xslx\" para visualizar os rótulos e a ordem dos rótulos de modo mais mastigado.\n",
    "\n",
    "Ao executar o docker compose além de ser levantado o ElasticSearch, também é levantada uma interface visual chamada Kibana.\n",
    "\n",
    "O Kibana é um frontend para facilitar o acionamento de algumas operações do ElasticSearch e controle de configurações específicas, observar métricas etc. Ela pode ser utilizada para fins de debug para quem tiver curiosidade acesso o URI: http://localhost:5601 após levantar o serviço com o docker compose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação do ambiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "import warnings\n",
    "import subprocess\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from collections import OrderedDict\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import sklearn\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import spacy\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 0: Subir Stack do Elastic (ElasticSearch e Kibana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download pt_core_news_sm\n",
    "# Caso o comando acima não funcione, execute-o no terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.call([\"docker\", \"compose\", \"up\", \"-d\"]) # Se esse comando falhar ou retornar 1, você pode executar ele diretamente no terminal para identificar o erro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 1: Baixar dados do Lupa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://docs.google.com/uc?export=download&confirm=t&id=1W067Md2EbvVzW1ufzFg17Hf7Y9cCZxxr\"\n",
    "filename = \"articles_lupa_lab_elasticsearch.zip\"\n",
    "data_path = \"data\"\n",
    "zip_file_path = f\"{data_path}/{filename}\"\n",
    "\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "# Download file\n",
    "with open(zip_file_path, \"wb\") as f:\n",
    "    f.write(requests.get(url, allow_redirects=True).content)\n",
    "\n",
    "# Extract file    \n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(data_path)\n",
    "    \n",
    "output_file = f\"{data_path}/articles_lupa.csv\"\n",
    "assert os.path.exists(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opções de pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessors:\n",
    "    STOPWORDS = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.spacy_nlp = spacy.load(\"pt_core_news_sm\")\n",
    "        # self.lemma = WordNetLemmatizer()\n",
    "        \n",
    "    \n",
    "    def remove_stopwords(self, text):\n",
    "        \"\"\"\n",
    "        Return :- String without stopwords\n",
    "        Input :- String\n",
    "        Output :- String\n",
    "        \"\"\"\n",
    "        # word tokenization\n",
    "        tokens = word_tokenize(text)\n",
    "        # remove stopwords from tokens\n",
    "        tokens = [word for word in tokens if word not in self.STOPWORDS]\n",
    "        # join list with space separator as string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def lemma(self, text):\n",
    "        return \" \".join([token.lemma_ for token in self.spacy_nlp(text)])\n",
    "    \n",
    "    def porter_stemmer(self, text):\n",
    "        # word tokenization\n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "        for index in range(len(tokens)):\n",
    "            # stem word to each word\n",
    "            stem_word = self.stemmer.stem(tokens[index])\n",
    "            # update tokens list with stem word\n",
    "            tokens[index] = stem_word\n",
    "\n",
    "        # join list with space separator as string\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    def lower_case(self, str):\n",
    "        return str.lower()\n",
    "\n",
    "    def remove_urls(self, text):\n",
    "        url_pattern = r'https?://\\S+|www\\.\\S+'\n",
    "        without_urls = re.sub(pattern=url_pattern, repl=' ', string=text)\n",
    "        return without_urls\n",
    "\n",
    "    def remove_numbers(self, text):\n",
    "        number_pattern = r'\\d+'\n",
    "        without_number = re.sub(pattern=number_pattern,\n",
    "    repl=\" \", string=text)\n",
    "        return without_number\n",
    "\n",
    "    def accented_to_ascii(self, text):\n",
    "        # apply unidecode function on text to convert\n",
    "        # accented characters to ASCII values\n",
    "        text = unidecode.unidecode(text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 2: Pré-processar os dados e gerar embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o modelo de embeddings\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "data_df_path = \"data/data_df.pkl\"\n",
    "\n",
    "# Selecione diferentes pré-processamentos se tiver curiosidade\n",
    "preprocessor = Preprocessors()\n",
    "    \n",
    "preprocessing_steps = [\n",
    "    preprocessor.lower_case,\n",
    "    preprocessor.remove_urls,\n",
    "    preprocessor.remove_numbers,\n",
    "    preprocessor.remove_stopwords,\n",
    "    preprocessor.lemma,\n",
    "    preprocessor.accented_to_ascii\n",
    "]\n",
    "\n",
    "if not os.path.exists(data_df_path):    \n",
    "    df = pd.read_csv(output_file, sep=\";\")[[\"Título\", \"Texto\", \"Data de Publicação\"]]\n",
    "    df[\"Data de Publicação\"] = df[\"Data de Publicação\"].apply(lambda str_date: datetime.strptime(str_date.split(\" - \")[0], \"%d.%m.%Y\"))\n",
    "    df.sort_values(\"Data de Publicação\", inplace=True, ascending=False)\n",
    "    df[\"Embeddings\"] = [None] * len(df)\n",
    "    df[\"id\"] = df.reset_index(drop=True).index\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        texto_completo = row[\"Texto\"].strip() + \"\\n\" + row[\"Título\"].strip()\n",
    "        \n",
    "        df.at[i, \"Texto completo\"] = texto_completo\n",
    "        texto_processado = texto_completo\n",
    "        for preprocessing_step in preprocessing_steps:\n",
    "            texto_processado = preprocessing_step(texto_processado)\n",
    "        \n",
    "        df.at[i, \"Texto processado\"] = texto_processado\n",
    "        embeddings = model.encode(texto_completo).tolist()\n",
    "        df.at[i, \"Embeddings\"] = embeddings\n",
    "        \n",
    "    print(\"Geração de embeddings finalizada.\")\n",
    "    \n",
    "    with open(data_df_path, \"wb\") as f:\n",
    "        df.to_pickle(f)\n",
    "else:\n",
    "    with open(data_df_path, \"rb\") as f:\n",
    "        df = pd.read_pickle(f)\n",
    "    print(\"Dataframe carregado de arquivo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 3: Indexar dados no ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(\n",
    "    hosts = [{'host': \"localhost\", 'port': 9200, \"scheme\": \"https\"}],\n",
    "    basic_auth=(\"elastic\",\"elastic\"),\n",
    "    verify_certs = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECREATE_INDEX = True\n",
    "\n",
    "index_name = \"verificacoes_lupa\"\n",
    "\n",
    "# Se a flag for True e se ele existir, deleta o índice\n",
    "if RECREATE_INDEX and es.indices.exists(index=index_name):\n",
    "    es.indices.delete(index=index_name)\n",
    "    print(f\"Índice '{index_name}' deletado.\")\n",
    "\n",
    "# Cria o índice e popula com os dados\n",
    "if not es.indices.exists(index=index_name):\n",
    "    es.indices.create(index=index_name, mappings={\n",
    "        \"properties\": {\n",
    "            \"id\": {\"type\": \"integer\"},\n",
    "            \"full_text\": {\"type\": \"text\"},\n",
    "            \"processed_text\": {\"type\": \"text\"},\n",
    "            \"embeddings\": {\"type\": \"dense_vector\", \"dims\": 384}\n",
    "        }\n",
    "    })\n",
    "    print(f\"Índice '{index_name}' criado.\")\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        es.index(index=index_name, id=row[\"id\"], body={\n",
    "            \"id\": row[\"id\"],\n",
    "            \"full_text\": row[\"Texto completo\"],\n",
    "            \"processed_text\": row[\"Texto processado\"],\n",
    "            \"embeddings\": row[\"Embeddings\"]\n",
    "        })\n",
    "    print(\"Índice preenchido.\")\n",
    "\n",
    "print(\"Indexação finalizada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 1: Criar query\n",
    "Preen\n",
    "\n",
    "Inspire-se nas notícias presente no csv (articles_lupa.csv) para gerar uma query interessante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 2: Executar buscas com todas as queries\n",
    "Agora com as queries obtidas de todos os grupos, realize cada uma das buscas para cada uma das queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/queries_fixadas.txt\", \"r\") as f:\n",
    "    queries_fixadas = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "# Preencha aqui as queries do grupo\n",
    "QUERY_1 = XXXXXX\n",
    "QUERY_2 = XXXXXX\n",
    "QUERY_3 = XXXXXX\n",
    "    \n",
    "queries_do_grupo = [QUERY_1, QUERY_2, QUERY_3]\n",
    "\n",
    "queries = [*queries_fixadas, *queries_do_grupo]\n",
    "\n",
    "assert len(queries) == 6\n",
    "\n",
    "all_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Busca Léxica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_search(queries):\n",
    "    lexical_results = {}\n",
    "    for query in queries:\n",
    "        # Pré-processa os dados\n",
    "        for preprocessing_step in preprocessing_steps:\n",
    "            query = preprocessing_step(query)\n",
    "        \n",
    "        search_query = {\n",
    "            \"query\": {\n",
    "                \"match\": {\n",
    "                    \"processed_text\": query\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        response = es.search(index=index_name, body=search_query)\n",
    "\n",
    "        hits_results = []\n",
    "        for hit in response[\"hits\"][\"hits\"][:10]:\n",
    "            hits_results.append((hit[\"_source\"][\"id\"], hit[\"_score\"]))\n",
    "        lexical_results[query] = hits_results\n",
    "        \n",
    "    return lexical_results\n",
    "\n",
    "all_results[\"lexical\"] = lexical_search(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Busca Semântica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(queries):\n",
    "    semantic_results = {}\n",
    "    \n",
    "    for query in queries:\n",
    "        # Pré-processa os dados\n",
    "        for preprocessing_step in preprocessing_steps:\n",
    "            query = preprocessing_step(query)\n",
    "            \n",
    "        query_vector = model.encode(query).tolist()\n",
    "        \n",
    "        search_query = {\n",
    "            \"query\": {\n",
    "                \"script_score\": {\n",
    "                    \"query\": {\"match_all\": {}},\n",
    "                    \"script\": {\n",
    "                        \"source\": \"cosineSimilarity(params.query_vector, 'embeddings') + 1.0\",\n",
    "                        \"params\": {\"query_vector\": query_vector}\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        response = es.search(index=index_name, body=search_query)\n",
    "        hits_results = []\n",
    "        for hit in response[\"hits\"][\"hits\"][:10]:\n",
    "            hits_results.append((hit[\"_source\"][\"id\"], hit[\"_score\"]))\n",
    "            # print(hit[\"_source\"], \"Score:\", hit[\"_score\"])\n",
    "        semantic_results[query] = hits_results\n",
    "\n",
    "    return semantic_results\n",
    "\n",
    "    # Perform vector similarity search\n",
    "\n",
    "all_results[\"semantic\"] = semantic_search(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Busca Híbrida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search(queries):\n",
    "    ## TODO: Implementar busca híbrida\n",
    "    pass\n",
    "\n",
    "all_results[\"hybrid\"] = hybrid_search(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Busca Criativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creative_search(queries):\n",
    "    ## TODO: Implementar busca híbrida\n",
    "    pass\n",
    "\n",
    "all_results[\"creative\"] = creative_search(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 3: Rotular dados da planilha para avaliar métodos de busca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results_df = pd.DataFrame(all_results)\n",
    "search_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função auxiliar que mapea o doc id para o texto correspondente da notícia\n",
    "def get_mapping_doc_id_to_text(data):\n",
    "    mapping_key_to_text = {}\n",
    "    for search_type in data.keys():\n",
    "        for query in data[search_type].keys():\n",
    "            for result in data[search_type][query]:\n",
    "                mapping_key_to_text[result[0]] = df.iloc[result[0]][\"Texto completo\"]\n",
    "    return mapping_key_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_results[\"lexical\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results[\"lexical\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que estrutura os dados para serem salvos em um arquivo Excel para rotulação\n",
    "def structure_data_to_excel_for_labeling(data, map_doc_id_to_text, query_to_idx, filename=\"search_results_for_labeling.xlsx\"):\n",
    "    with pd.ExcelWriter(filename, engine=\"xlsxwriter\") as writer:\n",
    "        for query, query_idx_str in query_to_idx.items():\n",
    "            rows = []\n",
    "            \n",
    "            lexical_results = data.get(\"lexical\", {}).get(query, [])\n",
    "            semantic_results = data.get(\"semantic\", {}).get(query, [])\n",
    "            hybrid_results = data.get(\"hybrid\", {}).get(query, [])\n",
    "            creative_results = data.get(\"creative\", {}).get(query, [])\n",
    "            \n",
    "            all_results = [*lexical_results, *semantic_results, *hybrid_results, *creative_results]\n",
    "            \n",
    "            document_ids = sorted(list({document_id for (document_id, _) in all_results}))\n",
    "            \n",
    "            max_len = max(len(lexical_results), len(semantic_results), len(hybrid_results), len(creative_results))\n",
    "            lexical_results += [(\"\", \"\")] * (max_len - len(lexical_results))\n",
    "            semantic_results += [(\"\", \"\")] * (max_len - len(semantic_results))\n",
    "            hybrid_results += [(\"\", \"\")] * (max_len - len(hybrid_results))\n",
    "            creative_results += [(\"\", \"\")] * (max_len - len(creative_results))\n",
    "            \n",
    "            for document_id in document_ids:\n",
    "                rows.append([document_id, map_doc_id_to_text[document_id], \"\"])\n",
    "            \n",
    "            df = pd.DataFrame(rows, columns=[\"ID\", \"Resultados\", \"Avaliação\"])\n",
    "            \n",
    "            workbook = writer.book\n",
    "            # worksheet = workbook.add_worksheet(query[:30])\n",
    "            worksheet = workbook.add_worksheet(query_idx_str)\n",
    "            writer.sheets[query] = worksheet\n",
    "            \n",
    "            # Format for big header\n",
    "            merge_format = workbook.add_format({\n",
    "                'bold': True,\n",
    "                'align': 'center',\n",
    "                'valign': 'vcenter',\n",
    "                'font_size': 14,\n",
    "                'bg_color': '#D9E1F2',\n",
    "                'border': 1\n",
    "            })\n",
    "            worksheet.merge_range(0, 0, 0, 6, f\"Query: {query}\", merge_format)\n",
    "            \n",
    "            # Format for column headers\n",
    "            header_format = workbook.add_format({\n",
    "                'bold': True,\n",
    "                'bg_color': '#B4C6E7',\n",
    "                'border': 1,\n",
    "                'align': 'center',\n",
    "                'valign': 'vcenter'\n",
    "            })\n",
    "            \n",
    "            # Write column headers\n",
    "            worksheet.write(1, 0, \"ID\", header_format)\n",
    "            worksheet.merge_range(1, 1, 1, 5, \"Resultados\", header_format)\n",
    "            worksheet.write(1, 6, \"Avaliação\", header_format)\n",
    "                \n",
    "            # Format for data cells\n",
    "            data_format = workbook.add_format({'border': 1})\n",
    "            \n",
    "            for row_num, row_data in enumerate(df.values):\n",
    "                # print(text)\n",
    "                worksheet.write(row_num + 2, 0, row_data[0], data_format)\n",
    "                worksheet.merge_range(row_num + 2, 1, row_num + 2, 5, row_data[1], data_format)  # Merge B:F for \"Review\"\n",
    "                \n",
    "            \n",
    "            # Add dropdown to \"Review\" columns\n",
    "            dropdown_format = workbook.add_format({'border': 1, 'bg_color': '#E2EFDA'})\n",
    "            for col in [6]:\n",
    "                dropdown_range = f\"{chr(65 + col)}3:{chr(65 + col)}{len(df) + 2}\"\n",
    "                worksheet.data_validation(dropdown_range, {\n",
    "                    'validate': 'list',\n",
    "                    'source': ['0', '1', '2'],\n",
    "                    'input_message': 'Select a review option (0, 1, 2)'\n",
    "                })\n",
    "                for row_num in range(2, len(df) + 2):\n",
    "                    worksheet.write(row_num, col, \"\", dropdown_format)\n",
    "            \n",
    "            # Adjust column width\n",
    "            for i, column in enumerate(df.columns):\n",
    "                worksheet.set_column(i, i, max(15, len(column) + 2))\n",
    "    \n",
    "    print(f\"Data written to {filename}\")\n",
    "\n",
    "all_queries = []\n",
    "for search_type in all_results:\n",
    "    if not all_queries:\n",
    "        all_queries = sorted(list(all_results[search_type].keys()))\n",
    "    assert all_queries == sorted(list(all_results[search_type].keys()))\n",
    "\n",
    "query_to_idx = OrderedDict()\n",
    "for idx, query in enumerate(all_queries):\n",
    "    query_to_idx[query] = f\"query_{idx}\"\n",
    "\n",
    "# Convert and save to Excel\n",
    "labeling_filename = \"search_results_for_labeling.xlsx\"\n",
    "structure_data_to_excel_for_labeling(all_results, get_mapping_doc_id_to_text(all_results), query_to_idx, labeling_filename)\n",
    "\n",
    "# Rotule o arquivo search_results_for_labeling.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 4: Após rotulado o arquivo execute o código abaixo para computar o NDCG score dos diferentes métodos de busca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o arquivo rotulado\n",
    "all_sheets_labels = pd.read_excel(labeling_filename, sheet_name=None, skiprows=1)\n",
    "labeling_df = {query_key: all_sheets_labels[query_key][[\"ID\", \"Avaliação\"]].set_index(\"ID\") for query_key in all_sheets_labels.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que salva os resultados obtido no Excel para uma melhor visualização\n",
    "def structure_data_to_excel(data, labeling_df, query_to_idx, filename=\"search_results.xlsx\"):\n",
    "    with pd.ExcelWriter(filename, engine=\"xlsxwriter\") as writer:\n",
    "        for query, query_idx_str in query_to_idx.items():\n",
    "            rows = []\n",
    "            \n",
    "            lexical_results = data.get(\"lexical\", {}).get(query, [])\n",
    "            semantic_results = data.get(\"semantic\", {}).get(query, [])\n",
    "            hybrid_results = data.get(\"hybrid\", {}).get(query, [])\n",
    "            creative_results = data.get(\"creative\", {}).get(query, [])\n",
    "            \n",
    "            max_len = max(len(lexical_results), len(semantic_results))\n",
    "            lexical_results += [(\"\", \"\")] * (max_len - len(lexical_results))\n",
    "            semantic_results += [(\"\", \"\")] * (max_len - len(semantic_results))\n",
    "            hybrid_results += [(\"\", \"\")] * (max_len - len(hybrid_results))\n",
    "            creative_results += [(\"\", \"\")] * (max_len - len(creative_results))\n",
    "            \n",
    "            for (lex_res, lex_score), (sem_res, sem_score), (hyb_res, hyb_score), (cre_res, cre_score) in zip(lexical_results, semantic_results, hybrid_results, creative_results):\n",
    "                cur_labeling_df = labeling_df[query_idx_str]\n",
    "\n",
    "                rows.append([\n",
    "                    lex_res, lex_score, cur_labeling_df.loc[lex_res][\"Avaliação\"],\n",
    "                    sem_res, sem_score, cur_labeling_df.loc[sem_res][\"Avaliação\"],\n",
    "                    hyb_res, hyb_score, cur_labeling_df.loc[hyb_res][\"Avaliação\"],\n",
    "                    cre_res, cre_score, cur_labeling_df.loc[cre_res][\"Avaliação\"]]\n",
    "                )\n",
    "            \n",
    "            df = pd.DataFrame(rows, columns=[\"Lexical Result\", \"Lexical Score\", \"Review\", \"Semantic Result\", \"Semantic Score\", \"Review\", \"Hybrid Result\", \"Hybrid Score\", \"Review\", \"Creative Result\", \"Creative Score\", \"Review\"])\n",
    "            workbook = writer.book\n",
    "            # worksheet = workbook.add_worksheet(query[:30])\n",
    "            worksheet = workbook.add_worksheet(query_idx_str)\n",
    "            \n",
    "            \n",
    "            # writer.sheets[query] = worksheet\n",
    "            \n",
    "            # Format for big header\n",
    "            merge_format = workbook.add_format({\n",
    "                'bold': True,\n",
    "                'align': 'center',\n",
    "                'valign': 'vcenter',\n",
    "                'font_size': 14,\n",
    "                'bg_color': '#D9E1F2',\n",
    "                'border': 1\n",
    "            })\n",
    "            worksheet.merge_range(0, 0, 0, 5, f\"Query: {query}\", merge_format)\n",
    "            \n",
    "            # Format for column headers\n",
    "            header_format = workbook.add_format({\n",
    "                'bold': True,\n",
    "                'bg_color': '#B4C6E7',\n",
    "                'border': 1,\n",
    "                'align': 'center',\n",
    "                'valign': 'vcenter'\n",
    "            })\n",
    "            \n",
    "            # Write column headers\n",
    "            for col_num, column_name in enumerate(df.columns):\n",
    "                worksheet.write(1, col_num, column_name, header_format)\n",
    "            \n",
    "            # Format for data cells\n",
    "            data_format = workbook.add_format({'border': 1})\n",
    "            \n",
    "            # Write data\n",
    "            for row_num, row_data in enumerate(df.values):\n",
    "                for idx, inner_data in enumerate(row_data):\n",
    "                    worksheet.write(row_num + 2, idx, inner_data, data_format)\n",
    "                    \n",
    "            # Adjust column width\n",
    "            for i, column in enumerate(df.columns):\n",
    "                worksheet.set_column(i, i, max(15, len(column) + 2))\n",
    "        \n",
    "    print(f\"Data written to {filename}\")\n",
    "\n",
    "# Convert and save to Excel\n",
    "structure_data_to_excel(all_results, labeling_df, query_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação da ordem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_all_ndcg(data, query_to_idx, labeling_df):\n",
    "    ndcg_scores = {}\n",
    "    \n",
    "    for search_type in data.keys():\n",
    "        all_labels = {}\n",
    "        for query, query_idx_str in query_to_idx.items():\n",
    "            search_results = data[search_type][query]\n",
    "            scores = [int(labeling_df[query_idx_str].loc[doc_id][\"Avaliação\"]) for doc_id, _ in search_results]\n",
    "            all_labels[query] = sklearn.metrics.ndcg_score([scores], [sorted(scores,reverse=True)])\n",
    "        ndcg_scores[search_type] = all_labels\n",
    "\n",
    "    return ndcg_scores\n",
    "\n",
    "# Computa o score NDCG@10\n",
    "def compute_mean_ndcg(data, query_to_idx, labeling_df):\n",
    "    ndcg_scores = {}\n",
    "    \n",
    "    for search_type in data.keys():\n",
    "        all_labels = []\n",
    "        for query, query_idx_str in query_to_idx.items():\n",
    "            search_results = data[search_type][query]\n",
    "            scores = [int(labeling_df[query_idx_str].loc[doc_id][\"Avaliação\"]) for doc_id, _ in search_results]\n",
    "            all_labels.append(scores)\n",
    "        ndcg_scores[search_type] = sklearn.metrics.ndcg_score(all_labels, [sorted(score_group,reverse=True) for score_group in all_labels])\n",
    "    \n",
    "    return ndcg_scores\n",
    "\n",
    "mean_ndcg_results = compute_mean_ndcg(all_results, query_to_idx, labeling_df)\n",
    "all_ndcg_results = compute_all_ndcg(all_results, query_to_idx, labeling_df)\n",
    "\n",
    "search_keys = [\"lexical\", \"semantic\", \"hybrid\", \"creative\"]\n",
    "print(\"NDCG@10 Médio\")\n",
    "for key in search_keys:\n",
    "    print(f\"\\tBusca {key}: {(100 * mean_ndcg_results[key]):.2f}%\")\n",
    "print(\"\\n----------------\\n\")\n",
    "print(\"NDCG@10 para cada query\")\n",
    "for key in search_keys:\n",
    "    print(f\"{key}:\")\n",
    "    for query, ndcg_score in all_ndcg_results[key].items():\n",
    "        print(f\"\\tQuery '{query}': {(100 * ndcg_score):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação da qualidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean(data, query_to_idx, labeling_df):\n",
    "    ndcg_scores = {}\n",
    "    \n",
    "    for search_type in data.keys():\n",
    "        all_labels = {}\n",
    "        for query, query_idx_str in query_to_idx.items():\n",
    "            search_results = data[search_type][query]\n",
    "            scores = [int(labeling_df[query_idx_str].loc[doc_id][\"Avaliação\"]) for doc_id, _ in search_results]\n",
    "            all_labels[query] = sum(scores)/(sum([2] * len(scores)))\n",
    "        ndcg_scores[search_type] = all_labels\n",
    "    \n",
    "    return ndcg_scores\n",
    "\n",
    "def compute_mean_average(data, query_to_idx, labeling_df):\n",
    "    mean_average_scores = {}\n",
    "    \n",
    "    for search_type in data.keys():\n",
    "        all_labels = []\n",
    "        for query, query_idx_str in query_to_idx.items():\n",
    "            search_results = data[search_type][query]\n",
    "            scores = [int(labeling_df[query_idx_str].loc[doc_id][\"Avaliação\"]) for doc_id, _ in search_results]\n",
    "            all_labels.append(sum(scores)/(sum([2] * len(scores))))\n",
    "        mean_average_scores[search_type] = sum(all_labels)/len(all_labels)\n",
    "    \n",
    "    return mean_average_scores\n",
    "\n",
    "mean_average_results = compute_mean_average(all_results, query_to_idx, labeling_df)\n",
    "# all_ndcg_results = compute_mean(all_results, query_to_idx, labeling_df)\n",
    "\n",
    "search_keys = [\"lexical\", \"semantic\", \"hybrid\", \"creative\"]\n",
    "print(\"Média por busca\")\n",
    "for key in search_keys:\n",
    "    print(f\"\\tBusca {key}: {(100 * mean_average_results[key]):.2f}%\")\n",
    "print(\"\\n----------------\\n\")\n",
    "print(\"Média por query e por busca\")\n",
    "for key in search_keys:\n",
    "    print(f\"{key}:\")\n",
    "    for query, ndcg_score in all_ndcg_results[key].items():\n",
    "        print(f\"\\tQuery '{query}': {(100 * ndcg_score):.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analyze-pdf-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
